{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The notebook aims to implement the procedure for training a RNN to teach addition of 2 Numbers in binary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.autograd as grad\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as Func\n",
    "from torch.autograd import Variable\n",
    "np.random.seed(seed=42)\n",
    "from numpy import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_train = 2000\n",
    "seq_len = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data(no_train_data, seq_len):\n",
    "    max_int = 2**(seq_len-1)\n",
    "    \n",
    "    format_str = '{:0' + str(seq_len) + 'b}'\n",
    "    nb_inputs = 2\n",
    "    nb_output = 1\n",
    "    \n",
    "    x = np.zeros((no_train_data,seq_len,nb_inputs))\n",
    "    y = np.zeros((no_train_data,seq_len,nb_output))\n",
    "    \n",
    "    for i in range(no_train_data):\n",
    "        nb1 = np.random.randint(0,max_int)\n",
    "        nb2 = np.random.randint(0,max_int)\n",
    "        \n",
    "        x[i,:,0] = list(reversed([int(b) for b in format_str.format(nb1)]))\n",
    "        x[i,:,1] = list(reversed([int(b) for b in format_str.format(nb2)]))\n",
    "        y[i,:,0] = list(reversed([int(b) for b in format_str.format(nb1+nb2)]))\n",
    "        \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = create_train_data(2000,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 7, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = ''.join([str(int(d)) for d in x_train[0,:,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(''.join(reversed(x_test)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recurrent(nn.Module):\n",
    "    def __init__(self,in_dim, hid_dim, out_dim, n_layer):\n",
    "        super(Recurrent,self).__init__()\n",
    "        \n",
    "        self.in_dim , self.hid_dim, self.out_dim, self.layer = in_dim, hid_dim, out_dim, n_layer\n",
    "        \n",
    "        self.rnn = nn.RNN(in_dim, hid_dim, n_layer, batch_first=True, nonlinearity='relu')\n",
    "        self.linear = nn.Linear(hid_dim, out_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        # define the batch size\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # initialize the hidden layer for the first input\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        \n",
    "        # passing in th einput and hidden state into model to get output\n",
    "        out, hidden = self.rnn(x,hidden)\n",
    "\n",
    "        \n",
    "        # reshaping the putput to fit into fully connected layers\n",
    "        out = out.contiguous()\n",
    "        out = self.linear(out)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self,batch_size):\n",
    "        return torch.zeros(self.layer,batch_size,self.hid_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN varibales\n",
    "in_dim = 2\n",
    "hid_dim = 10\n",
    "out_dim = 1\n",
    "layers = 1\n",
    "\n",
    "# define the model\n",
    "rnn_model = Recurrent(in_dim,hid_dim,out_dim,layers)\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "learn_rate = 0.01\n",
    "optimizer = torch.optim.Adam(rnn_model.parameters(),lr=learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = torch.from_numpy(x_train).float(), torch.from_numpy(y_train).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = rnn_model(Variable(x_train[np.random.choice(2000, 1),:,:]))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_func(pred,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_train(epochs):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        loss = 0\n",
    "        # choose a random point\n",
    "        point = np.random.choice(x_train.shape[0],1)\n",
    "        \n",
    "        # convert the train and test data into variables\n",
    "        x,y = Variable(x_train[point,:,:]), y_train[point,:,:]\n",
    "#         print(x.shape)\n",
    "        #print(y.shape)\n",
    "        \n",
    "        # set the gradient of the model to zero\n",
    "        rnn_model.zero_grad()\n",
    "        \n",
    "        # predict the output\n",
    "        output,hidden = rnn_model(x)\n",
    "        #print(output[0].shape)\n",
    "        \n",
    "        # calculate the loss\n",
    "        loss = loss_func(output,y)\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss_list.append(loss.data)\n",
    "        \n",
    "        loss += loss\n",
    "        \n",
    "        if epoch %100 ==0:\n",
    "            print('Epoch :{}    Loss :{}'.format(epoch,loss/epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :0    Loss :inf\n",
      "Epoch :100    Loss :0.005042221397161484\n",
      "Epoch :200    Loss :0.0017301571788266301\n",
      "Epoch :300    Loss :0.0012416396057233214\n",
      "Epoch :400    Loss :0.0003893266257364303\n",
      "Epoch :500    Loss :0.0007003377540968359\n",
      "Epoch :600    Loss :0.00044703681487590075\n",
      "Epoch :700    Loss :0.0007622572593390942\n",
      "Epoch :800    Loss :0.00016713107470422983\n",
      "Epoch :900    Loss :7.174230177042773e-06\n",
      "Epoch :1000    Loss :0.00018410527263768017\n",
      "Epoch :1100    Loss :2.2073569198255427e-05\n",
      "Epoch :1200    Loss :1.4925373761798255e-05\n",
      "Epoch :1300    Loss :2.079520527331624e-06\n",
      "Epoch :1400    Loss :7.828770662854367e-07\n",
      "Epoch :1500    Loss :2.9669987270608544e-05\n",
      "Epoch :1600    Loss :4.591920969687635e-06\n",
      "Epoch :1700    Loss :1.6732770745875314e-05\n",
      "Epoch :1800    Loss :1.2294099178689066e-05\n",
      "Epoch :1900    Loss :1.8242560884118575e-07\n",
      "Epoch :2000    Loss :6.431493602576666e-06\n",
      "Epoch :2100    Loss :3.4325594242545776e-06\n",
      "Epoch :2200    Loss :1.3748418723480427e-06\n",
      "Epoch :2300    Loss :3.1019633297546534e-06\n",
      "Epoch :2400    Loss :3.689295908770873e-06\n",
      "Epoch :2500    Loss :1.1819614883279428e-05\n",
      "Epoch :2600    Loss :0.0001530103327240795\n",
      "Epoch :2700    Loss :9.296788903156994e-07\n",
      "Epoch :2800    Loss :2.516869699320523e-06\n",
      "Epoch :2900    Loss :3.503321579501062e-07\n",
      "Epoch :3000    Loss :8.45022363193948e-09\n",
      "Epoch :3100    Loss :7.572143658762798e-07\n",
      "Epoch :3200    Loss :6.957531013540574e-07\n",
      "Epoch :3300    Loss :4.0972696524477215e-07\n",
      "Epoch :3400    Loss :1.1377009556667872e-08\n",
      "Epoch :3500    Loss :4.405361266890395e-07\n",
      "Epoch :3600    Loss :5.63714991130837e-07\n",
      "Epoch :3700    Loss :2.911161232077575e-07\n",
      "Epoch :3800    Loss :3.661036487301317e-07\n",
      "Epoch :3900    Loss :3.840726208181877e-07\n",
      "Epoch :4000    Loss :5.798876827611821e-07\n",
      "Epoch :4100    Loss :2.2003769117873162e-07\n",
      "Epoch :4200    Loss :4.0437646475766087e-07\n",
      "Epoch :4300    Loss :7.305067217799888e-09\n",
      "Epoch :4400    Loss :2.3909413471301377e-07\n",
      "Epoch :4500    Loss :1.9070436962920212e-07\n",
      "Epoch :4600    Loss :2.92455808903469e-07\n",
      "Epoch :4700    Loss :1.5312332379835425e-07\n",
      "Epoch :4800    Loss :2.394495446367273e-08\n",
      "Epoch :4900    Loss :1.5169081546417829e-09\n",
      "Epoch :5000    Loss :3.587110484204459e-07\n",
      "Epoch :5100    Loss :2.3310597896397667e-07\n",
      "Epoch :5200    Loss :7.696844050997242e-08\n",
      "Epoch :5300    Loss :1.7066716040403662e-08\n",
      "Epoch :5400    Loss :4.375972650905169e-08\n",
      "Epoch :5500    Loss :1.1198660843092512e-07\n",
      "Epoch :5600    Loss :7.118320866084105e-08\n",
      "Epoch :5700    Loss :4.9553172232208453e-08\n",
      "Epoch :5800    Loss :3.874013287941125e-08\n",
      "Epoch :5900    Loss :8.309300625342075e-08\n",
      "Epoch :6000    Loss :5.1439020154475656e-08\n",
      "Epoch :6100    Loss :8.39486613557483e-09\n",
      "Epoch :6200    Loss :4.284922638930766e-08\n",
      "Epoch :6300    Loss :1.4938853487578285e-09\n",
      "Epoch :6400    Loss :3.9006202712243976e-08\n",
      "Epoch :6500    Loss :6.676250308146336e-08\n",
      "Epoch :6600    Loss :3.810090021261203e-09\n",
      "Epoch :6700    Loss :6.8472840730748885e-09\n",
      "Epoch :6800    Loss :4.974739908902848e-08\n",
      "Epoch :6900    Loss :1.4726423414046508e-09\n",
      "Epoch :7000    Loss :2.99754567834043e-08\n",
      "Epoch :7100    Loss :5.066986705060117e-05\n",
      "Epoch :7200    Loss :2.651719296409283e-05\n",
      "Epoch :7300    Loss :5.569090149037947e-07\n",
      "Epoch :7400    Loss :8.364252721548837e-07\n",
      "Epoch :7500    Loss :8.757562000027974e-07\n",
      "Epoch :7600    Loss :6.283361386749675e-09\n",
      "Epoch :7700    Loss :8.082136737641576e-09\n",
      "Epoch :7800    Loss :1.1373683150850411e-07\n",
      "Epoch :7900    Loss :6.319592671388818e-07\n",
      "Epoch :8000    Loss :1.1327236393299245e-07\n",
      "Epoch :8100    Loss :9.955682571671787e-07\n",
      "Epoch :8200    Loss :1.2072322874701058e-07\n",
      "Epoch :8300    Loss :1.6094463717308827e-07\n",
      "Epoch :8400    Loss :1.285437036813164e-07\n",
      "Epoch :8500    Loss :6.063280579837738e-07\n",
      "Epoch :8600    Loss :2.660440479029802e-10\n",
      "Epoch :8700    Loss :3.899007197105675e-07\n",
      "Epoch :8800    Loss :2.453359293497215e-09\n",
      "Epoch :8900    Loss :7.860024453520964e-08\n",
      "Epoch :9000    Loss :7.303385984869237e-08\n",
      "Epoch :9100    Loss :9.622258545505247e-09\n",
      "Epoch :9200    Loss :2.6023249333206877e-08\n",
      "Epoch :9300    Loss :8.68195826342344e-09\n",
      "Epoch :9400    Loss :2.7970035176849706e-08\n",
      "Epoch :9500    Loss :5.377610179380099e-08\n",
      "Epoch :9600    Loss :1.4335707065882275e-09\n",
      "Epoch :9700    Loss :8.902057979653932e-10\n",
      "Epoch :9800    Loss :3.376161927803878e-08\n",
      "Epoch :9900    Loss :1.9059879008409553e-08\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "RNN_train(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1dd126d6988>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Output is \n",
      " [0. 0. 1. 1. 0. 0. 1.]\n",
      "Actual Output is \n",
      " [0. 0. 1. 1. 0. 0. 1.]\n",
      "#################################\n",
      "Predicted Output is \n",
      " [1. 1. 0. 1. 1. 1. 0.]\n",
      "Actual Output is \n",
      " [1. 1. 0. 1. 1. 1. 0.]\n",
      "#################################\n",
      "Predicted Output is \n",
      " [1. 1. 0. 0. 0. 1. 1.]\n",
      "Actual Output is \n",
      " [1. 1. 0. 0. 0. 1. 1.]\n",
      "#################################\n",
      "Predicted Output is \n",
      " [1. 1. 0. 1. 0. 1. 0.]\n",
      "Actual Output is \n",
      " [1. 1. 0. 1. 0. 1. 0.]\n",
      "#################################\n",
      "Predicted Output is \n",
      " [1. 0. 0. 1. 1. 1. 0.]\n",
      "Actual Output is \n",
      " [1. 0. 0. 1. 1. 1. 0.]\n",
      "#################################\n",
      "Predicted Output is \n",
      " [1. 0. 1. 0. 1. 0. 1.]\n",
      "Actual Output is \n",
      " [1. 0. 1. 0. 1. 0. 1.]\n",
      "#################################\n",
      "Predicted Output is \n",
      " [1. 1. 1. 1. 0. 0. 1.]\n",
      "Actual Output is \n",
      " [1. 1. 1. 1. 0. 0. 1.]\n",
      "#################################\n",
      "Predicted Output is \n",
      " [0. 1. 1. 1. 0. 0. 1.]\n",
      "Actual Output is \n",
      " [0. 1. 1. 1. 0. 0. 1.]\n",
      "#################################\n",
      "Predicted Output is \n",
      " [0. 0. 0. 1. 1. 0. 1.]\n",
      "Actual Output is \n",
      " [0. 0. 0. 1. 1. 0. 1.]\n",
      "#################################\n",
      "Predicted Output is \n",
      " [0. 1. 1. 1. 0. 0. 1.]\n",
      "Actual Output is \n",
      " [0. 1. 1. 1. 0. 0. 1.]\n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "# check the accuracy of the training RNN\n",
    "for i in range(10):\n",
    "    # choose a random point\n",
    "    point = np.random.choice(x_train.shape[0],1)\n",
    "        \n",
    "    # convert the train and test data into variables\n",
    "    x,y = Variable(x_train[point,:,:]), y_train[point,:,:]\n",
    "    output,hidden = rnn_model(x)\n",
    "    print('Predicted Output is \\n {}'.format((output.gt(0.5)[0]*1.).flatten().numpy()))\n",
    "    print('Actual Output is \\n {}'.format(y.numpy().ravel()))\n",
    "    print('#################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
